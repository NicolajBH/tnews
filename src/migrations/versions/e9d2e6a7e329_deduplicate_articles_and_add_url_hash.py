"""deduplicate_articles_and_add_url_hash

Revision ID: e9d2e6a7e329
Revises: a178f816a9b8
Create Date: 2025-04-29 10:52:41.450502

"""

from typing import Sequence, Union
from hashlib import sha256

from alembic import op
import sqlalchemy as sa
import sqlmodel


# revision identifiers, used by Alembic.
revision: str = "e9d2e6a7e329"
down_revision: Union[str, None] = "a178f816a9b8"
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "articles",
        sa.Column("url_hash", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
    )
    op.create_index(
        op.f("ix_articles_original_url"), "articles", ["original_url"], unique=False
    )
    op.create_index(
        op.f("ix_articles_url_hash"), "articles", ["url_hash"], unique=False
    )

    # add url hashes to existing articles
    bind = op.get_bind()
    session = sa.orm.Session(bind=bind)

    articles = session.execute(
        sa.text("SELECT id, original_url FROM articles")
    ).fetchall()
    for article_id, url in articles:
        normalized_url = url.rstrip("/").lower()
        url_hash = sha256(normalized_url.encode()).hexdigest()
        session.execute(
            sa.text("UPDATE articles SET url_hash = :hash WHERE id = :id"),
            {"hash": url_hash, "id": article_id},
        )
    session.commit()

    # get duplicate articles
    duplicate_query = """
    SELECT url_hash, COUNT(*) as count
    FROM articles
    GROUP BY url_hash
    HAVING COUNT(*) > 1
    """
    duplicate_hashes = session.execute(sa.text(duplicate_query)).fetchall()

    if duplicate_hashes:
        duplicates_processed = 0
        articles_removed = 0
        for url_hash, count in duplicate_hashes:
            dupes_query = """
            SELECT id, title, content_hash, pub_date, pub_date_raw, source_id, original_url, created_at, updated_at
            FROM articles
            WHERE url_hash = :hash
            ORDER BY created_at ASC
            """
            dupes = session.execute(sa.text(dupes_query), {"hash": url_hash}).fetchall()

            earliest_created = dupes[0][7]
            latest = max(dupes, key=lambda x: x[8])
            latest_title = latest[1]
            latest_updated_at = latest[8]

            all_ids = [d[0] for d in dupes]
            all_ids_str = ",".join(str(id) for id in all_ids)

            category_query = """
            SELECT DISTINCT category_id, created_at
            FROM articlecategories
            WHERE article_id IN (:ids)
            """

            category_associations = session.execute(
                sa.text(category_query), {"ids": all_ids_str}
            ).fetchall()

            for article_id in all_ids:
                session.execute(
                    sa.text("DELETE FROM articlecategories WHERE article_id = :id"),
                    {"id": article_id},
                )

                session.execute(
                    sa.text("DELETE FROM articles WHERE id = :id"), {"id": article_id}
                )

            new_article_query = """
            INSERT INTO articles (
                title, content_hash, pub_date, pub_date_raw, source_id,
                original_url, url_hash, created_at, updated_at
            ) VALUES (
                :title, :content_hash, :pub_date, :pub_date_raw, :source_id,
                :original_url, :url_hash, :created_at, :updated_at
            ) RETURNING id
            """

            result = session.execute(
                sa.text(new_article_query),
                {
                    "title": latest_title,
                    "content_hash": latest[2],
                    "pub_date": latest[3],
                    "pub_date_raw": latest[4],
                    "source_id": latest[5],
                    "original_url": latest[6],
                    "url_hash": url_hash,
                    "created_at": earliest_created,
                    "updated_at": latest_updated_at,
                },
            ).fetchone()

            new_id = result[0]

            for category_id, created_at in category_associations:
                session.execute(
                    sa.text("""
                    INSERT INTO articlecategories (article_id, category_id, created_at)
                    VALUES (:article_id, :category_id, :created_at)
                    """),
                    {
                        "article_id": new_id,
                        "category_id": category_id,
                        "created_at": created_at,
                    },
                )
            duplicates_processed += 1
            articles_removed += len(all_ids) - 1

            if duplicates_processed % 20 == 0:
                session.commit()
        session.commit()

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f("ix_articles_url_hash"), table_name="articles")
    op.drop_index(op.f("ix_articles_original_url"), table_name="articles")
    op.drop_column("articles", "url_hash")
    # ### end Alembic commands ###
